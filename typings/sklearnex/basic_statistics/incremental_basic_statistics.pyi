"""
This type stub file was generated by pyright.
"""

from sklearn.base import BaseEstimator
from daal4py.sklearn._n_jobs_support import control_n_jobs
from daal4py.sklearn._utils import sklearn_check_version
from ..base import oneDALEstimator

if sklearn_check_version("1.2"):
    ...
@control_n_jobs(decorated_methods=["partial_fit", "_onedal_finalize_fit"])
class IncrementalBasicStatistics(oneDALEstimator, BaseEstimator):
    """
    Incremental estimator for basic statistics.

    Calculates basic statistics on the given data, allows for computation
    when the data are split into batches. The user can use ``partial_fit``
    method to provide a single batch of data or use the ``fit`` method to
    provide the entire dataset.

    Parameters
    ----------
    result_options : str or list, default=str('all')
        List of statistics to compute.

    batch_size : int, default=None
        The number of samples to use for each batch. Only used when calling
        ``fit``. If ``batch_size`` is ``None``, then ``batch_size``
        is inferred from the data and set to ``5 * n_features``.

    Attributes
    ----------
        min_ : ndarray of shape (n_features,)
            Minimum of each feature over all samples.

        max_ : ndarray of shape (n_features,)
            Maximum of each feature over all samples.

        sum_ : ndarray of shape (n_features,)
            Sum of each feature over all samples.

        mean_ : ndarray of shape (n_features,)
            Mean of each feature over all samples.

        variance_ : ndarray of shape (n_features,)
            Variance of each feature over all samples.

        variation_ : ndarray of shape (n_features,)
            Variation of each feature over all samples.

        sum_squares_ : ndarray of shape (n_features,)
            Sum of squares for each feature over all samples.

        standard_deviation_ : ndarray of shape (n_features,)
            Standard deviation of each feature over all samples.

        sum_squares_centered_ : ndarray of shape (n_features,)
            Centered sum of squares for each feature over all samples.

        second_order_raw_moment_ : ndarray of shape (n_features,)
            Second order moment of each feature over all samples.

        n_samples_seen_ : int
            The number of samples processed by the estimator. Will be reset
            on new calls to ``fit``, but increments across ``partial_fit``
            calls.

        batch_size_ : int
            Inferred batch size from ``batch_size``.

        n_features_in_ : int
            Number of features seen during ``fit`` or  ``partial_fit``.

    Notes
    -----
    Attribute exists only if corresponding result option has been provided.

    Names of attributes without the trailing underscore are supported
    currently but deprecated in 2025.1 and will be removed in 2026.0.

    Sparse data formats are not supported. Input dtype must be ``float32`` or ``float64``.

    %incremental_serialization_note%

    Examples
    --------
    >>> import numpy as np
    >>> from sklearnex.basic_statistics import IncrementalBasicStatistics
    >>> incbs = IncrementalBasicStatistics(batch_size=1)
    >>> X = np.array([[1, 2], [3, 4]])
    >>> incbs.partial_fit(X[:1])
    >>> incbs.partial_fit(X[1:])
    >>> incbs.sum_
    np.array([4., 6.])
    >>> incbs.min_
    np.array([1., 2.])
    >>> incbs.fit(X)
    >>> incbs.sum_
    np.array([4., 6.])
    >>> incbs.max_
    np.array([3., 4.])
    """
    __doc__ = ...
    _onedal_incremental_basic_statistics = ...
    if sklearn_check_version("1.2"):
        _parameter_constraints: dict = ...
    def __init__(self, result_options=..., batch_size=...) -> None:
        ...
    
    _onedal_cpu_supported = ...
    _onedal_gpu_supported = ...
    def __getattr__(self, attr): # -> Any:
        ...
    
    def partial_fit(self, X, sample_weight=..., check_input=...): # -> Self:
        """Incremental fit with X. All of X is processed as a single batch.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            Data for compute, where ``n_samples`` is the number of samples and
            ``n_features`` is the number of features.

        y : Ignored
            Not used, present for API consistency by convention.

        sample_weight : array-like of shape (n_samples,), default=None
            Weights for compute weighted statistics, where ``n_samples`` is the number of samples.

        check_input : bool, default=True
            Run ``check_array`` on X.

        Returns
        -------
        self : IncrementalBasicStatistics
            Returns the instance itself.
        """
        ...
    
    def fit(self, X, y=..., sample_weight=...): # -> Self:
        """Calculate statistics of X using minibatches of size ``batch_size``.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            Data for compute, where ``n_samples`` is the number of samples and
            ``n_features`` is the number of features.

        y : Ignored
            Not used, present for API consistency by convention.

        sample_weight : array-like of shape (n_samples,), default=None
            Weights for compute weighted statistics, where ``n_samples`` is the number of samples.

        Returns
        -------
        self : IncrementalBasicStatistics
            Returns the instance itself.
        """
        ...
    


