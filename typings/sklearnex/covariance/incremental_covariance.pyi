"""
This type stub file was generated by pyright.
"""

from sklearn.base import BaseEstimator
from daal4py.sklearn._n_jobs_support import control_n_jobs
from daal4py.sklearn._utils import sklearn_check_version
from .._device_offload import wrap_output_data
from ..base import oneDALEstimator

if sklearn_check_version("1.2"):
    ...
@control_n_jobs(decorated_methods=["partial_fit", "fit", "_onedal_finalize_fit"])
class IncrementalEmpiricalCovariance(oneDALEstimator, BaseEstimator):
    """
    Incremental maximum likelihood covariance estimator.

    Estimator that allows for the estimation when the data are split into
    batches. The user can use the ``partial_fit`` method to provide a
    single batch of data or use the ``fit`` method to provide the entire
    dataset.

    Parameters
    ----------
    store_precision : bool, default=False
        Specifies if the estimated precision is stored.

    assume_centered : bool, default=False
        If True, data are not centered before computation.
        Useful when working with data whose mean is almost, but not exactly
        zero.
        If False (default), data are centered before computation.

    batch_size : int, default=None
        The number of samples to use for each batch. Only used when calling
        ``fit``. If ``batch_size`` is ``None``, then ``batch_size``
        is inferred from the data and set to ``5 * n_features``, to provide
        a balance between approximation accuracy and memory consumption.

    copy : bool, default=True
        If False, X will be overwritten. ``copy=False`` can be used to
        save memory but is unsafe for general use.

    Attributes
    ----------
    location_ : ndarray of shape (n_features,)
        Estimated location, i.e. the estimated mean.

    covariance_ : ndarray of shape (n_features, n_features)
        Estimated covariance matrix

    n_samples_seen_ : int
        The number of samples processed by the estimator. Will be reset on
        new calls to ``fit``, but increments across ``partial_fit`` calls.

    batch_size_ : int
        Inferred batch size from ``batch_size``.

    n_features_in_ : int
        Number of features seen during ``fit`` or ``partial_fit``.

    Notes
    -----
    Sparse data formats are not supported. Input dtype must be ``float32`` or ``float64``.

    %incremental_serialization_note%

    Examples
    --------
    >>> import numpy as np
    >>> from sklearnex.covariance import IncrementalEmpiricalCovariance
    >>> inccov = IncrementalEmpiricalCovariance(batch_size=1)
    >>> X = np.array([[1, 2], [3, 4]])
    >>> inccov.partial_fit(X[:1])
    >>> inccov.partial_fit(X[1:])
    >>> inccov.covariance_
    np.array([[1., 1.],[1., 1.]])
    >>> inccov.location_
    np.array([2., 3.])
    >>> inccov.fit(X)
    >>> inccov.covariance_
    np.array([[1., 1.],[1., 1.]])
    >>> inccov.location_
    np.array([2., 3.])
    """
    __doc__ = ...
    _onedal_incremental_covariance = ...
    if sklearn_check_version("1.2"):
        _parameter_constraints: dict = ...
    get_precision = ...
    error_norm = ...
    def __init__(self, *, store_precision=..., assume_centered=..., batch_size=..., copy=...) -> None:
        ...
    
    @property
    def covariance_(self): # -> Any | tuple[Any, ...]:
        ...
    
    @property
    def location_(self): # -> Any:
        ...
    
    @wrap_output_data
    def score(self, X_test, y=...): # -> Float:
        ...
    
    def partial_fit(self, X, y=..., check_input=...): # -> Any:
        """
        Incremental fit with X. All of X is processed as a single batch.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            Training data, where `n_samples` is the number of samples and
            `n_features` is the number of features.

        y : Ignored
            Not used, present for API consistency by convention.

        check_input : bool, default=True
            Run check_array on X.

        Returns
        -------
        self : IncrementalEmpiricalCovariance
            Returns the instance itself.
        """
        ...
    
    def fit(self, X, y=...): # -> Any:
        """
        Fit the model with X, using minibatches of size ``batch_size``.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            Training data, where `n_samples` is the number of samples and
            `n_features` is the number of features.

        y : Ignored
            Not used, present for API consistency by convention.

        Returns
        -------
        self : IncrementalEmpiricalCovariance
            Returns the instance itself.
        """
        ...
    
    def mahalanobis(self, X): # -> dpnp_array | Any:
        ...
    
    _onedal_cpu_supported = ...
    _onedal_gpu_supported = ...


